{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "xtrain_glove = np.loadtxt('query_glove.csv',delimiter=\",\", dtype=float)\n",
    "\n",
    "# Reading 2048-d train features \n",
    "features_train_2048 = np.zeros((10000,2048))\n",
    "with open('./all/data/features_train/features_resnet1000intermediate_train.csv', 'r') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    for line in csv_reader:\n",
    "        image_name = line[0].strip(\".jpg\")[13:]\n",
    "        row = []\n",
    "        for i in range(len(line)):\n",
    "            if i > 0:\n",
    "                row.append(float(line[i]))\n",
    "        features_train_2048[int(image_name)] = row\n",
    "        \n",
    "# Reading 1000-d train features \n",
    "features_train_1000 = np.zeros((10000,1000))\n",
    "with open('./all/data/features_train/features_resnet1000_train.csv', 'r') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    for line in csv_reader:\n",
    "        image_name = line[0].strip(\".jpg\")[13:]\n",
    "        row = []\n",
    "        for i in range(len(line)):\n",
    "            if i > 0:\n",
    "                row.append(float(line[i]))\n",
    "        features_train_1000[int(image_name)] = row\n",
    "        \n",
    "# Find set of supercategories, categories \n",
    "supercategory_set = set()\n",
    "category_set = set()\n",
    "for i in range (10000):\n",
    "    file = open(\"./all/data/tags_train/\" + str(i) + \".txt\", \"r\")\n",
    "    lines = file.readlines() \n",
    "    for  line in lines:\n",
    "        words = line.strip().split(':')\n",
    "        supercategory_set.add(words[0])\n",
    "        category_set.add(words[1])\n",
    "    file.close()\n",
    "\n",
    "# mapping from (super) category to index\n",
    "supercategory_dict = {item:val for val, item in enumerate(supercategory_set)}\n",
    "category_dict = {item:val+1 for val, item in enumerate(category_set)}\n",
    "\n",
    "# Vectorize train tags\n",
    "train_tags = []\n",
    "for i in range (10000):\n",
    "    file = open(\"./all/data/tags_train/\" + str(i) + \".txt\", \"r\")\n",
    "    lines = file.readlines() \n",
    "    row = np.zeros(len(supercategory_set))\n",
    "    for line in lines:\n",
    "        words = line.strip().split(':')\n",
    "        supercategory_column = supercategory_dict.get(words[0])\n",
    "        category_index = category_dict.get(words[1])\n",
    "        row[supercategory_column] = category_index\n",
    "    train_tags.append(row)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_2048 = np.zeros((2000,2048))\n",
    "with open('./all/data/features_test/features_resnet1000intermediate_test.csv', 'r') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    for line in csv_reader:\n",
    "        image_name = line[0].strip(\".jpg\")[12:]\n",
    "        row = []\n",
    "        for i in range(len(line)):\n",
    "            if i > 0:\n",
    "                row.append(float(line[i]))\n",
    "        features_test_2048[int(image_name)] = row\n",
    "\n",
    "features_test_1000 = np.zeros((2000,1000))    \n",
    "with open('./all/data/features_test/features_resnet1000_test.csv', 'r') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    for line in csv_reader:\n",
    "        image_name = line[0].strip(\".jpg\")[12:]\n",
    "        row = []\n",
    "        for i in range(len(line)):\n",
    "            if i > 0:\n",
    "                row.append(float(line[i]))\n",
    "        features_test_1000[int(image_name)] = row\n",
    "\n",
    "# Vectorize test tags\n",
    "test_tags = []\n",
    "for i in range (2000):\n",
    "    file = open(\"./all/data/tags_test/\" + str(i) + \".txt\", \"r\")\n",
    "    lines = file.readlines() \n",
    "    row = np.zeros(len(supercategory_set))\n",
    "    for line in lines:\n",
    "        words = line.strip().split(':')\n",
    "        supercategory_column = supercategory_dict.get(words[0])\n",
    "        category_index = category_dict.get(words[1])\n",
    "        row[supercategory_column] = category_index\n",
    "    test_tags.append(row)\n",
    "    file.close()\n",
    "    \n",
    "\n",
    "xtest_glove = np.loadtxt('query_glove_test.csv',delimiter=\",\", dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_concat = np.concatenate((np.array(features_train_2048),np.array(features_train_1000)), axis=1)\n",
    "features_train_concat = np.concatenate((features_train_concat, np.array(train_tags)), axis=1)\n",
    "\n",
    "features_test_concat = np.concatenate((np.array(features_test_2048),np.array(features_test_1000)), axis=1)\n",
    "features_test_concat = np.concatenate((features_test_concat, np.array(test_tags)), axis=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_train_concat = StandardScaler().fit_transform(features_train_concat)\n",
    "features_test_concat = StandardScaler().fit_transform(features_test_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=-1, normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "clf_lr = LinearRegression(n_jobs=-1, fit_intercept = False)\n",
    "clf_lr.fit(features_train_concat,xtrain_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predict= clf_lr.predict(features_test_concat)\n",
    "\n",
    "rank_list = []\n",
    "for i in range (2000):\n",
    "    current_query = xtest_glove[i]\n",
    "    dist = []\n",
    "    for j in range(2000):\n",
    "        dist.append((np.linalg.norm(lr_predict[j]-current_query),j))\n",
    "    dist.sort()\n",
    "    rank_list.append([v for (k,v) in dist[:20]])\n",
    "\n",
    "def mergeTwenty(lst):\n",
    "    result = str(lst[0])+\".jpg\"\n",
    "    for i in range(1,len(lst)):\n",
    "        result += \" \" + str(lst[i]) + \".jpg\"\n",
    "    return result\n",
    "\n",
    "with open('linearR_std_reverse.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "    csv_writer.writerow([\"Descritpion_ID\", \"Top_20_Image_IDs\"])\n",
    "    for i in range(len(rank_list)):\n",
    "        csv_writer.writerow([str(i) + \".txt\", mergeTwenty(rank_list[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works.....\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "clf_knn_reverse = KNeighborsRegressor(n_neighbors=5,n_jobs=-1)\n",
    "clf_knn_reverse.fit(features_train_concat,xtrain_glove)\n",
    "knn_predict_reverse= clf_knn_reverse.predict(features_test_concat)\n",
    "\n",
    "rank_list = []\n",
    "for i in range (2000):\n",
    "    current_query = xtest_glove[i]\n",
    "    dist = []\n",
    "    for j in range(2000):\n",
    "        dist.append((np.linalg.norm(knn_predict_reverse[j]-current_query),j))\n",
    "    dist.sort()\n",
    "    rank_list.append([v for (k,v) in dist[:20]])\n",
    "\n",
    "def mergeTwenty(lst):\n",
    "    result = str(lst[0])+\".jpg\"\n",
    "    for i in range(1,len(lst)):\n",
    "        result += \" \" + str(lst[i]) + \".jpg\"\n",
    "    return result\n",
    "\n",
    "with open('knn_std_reverse.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "    csv_writer.writerow([\"Descritpion_ID\", \"Top_20_Image_IDs\"])\n",
    "    for i in range(len(rank_list)):\n",
    "        csv_writer.writerow([str(i) + \".txt\", mergeTwenty(rank_list[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "cls = KernelRidge(kernel='rbf',alpha=1.0)\n",
    "\n",
    "\n",
    "cls.fit(features_train_concat,xtrain_glove)\n",
    "lr_predict= cls.predict(features_test_concat)\n",
    "\n",
    "rank_list = []\n",
    "for i in range (2000):\n",
    "    current_query = xtest_glove[i]\n",
    "    dist = []\n",
    "    for j in range(2000):\n",
    "        dist.append((np.linalg.norm(lr_predict[j]-current_query),j))\n",
    "    dist.sort()\n",
    "    rank_list.append([v for (k,v) in dist[:20]])\n",
    "\n",
    "def mergeTwenty(lst):\n",
    "    result = str(lst[0])+\".jpg\"\n",
    "    for i in range(1,len(lst)):\n",
    "        result += \" \" + str(lst[i]) + \".jpg\"\n",
    "    return result\n",
    "\n",
    "with open('linearR_std_reverse.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "    csv_writer.writerow([\"Descritpion_ID\", \"Top_20_Image_IDs\"])\n",
    "    for i in range(len(rank_list)):\n",
    "        csv_writer.writerow([str(i) + \".txt\", mergeTwenty(rank_list[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "cls = KernelRidge(kernel='rbf',alpha=1.0)\n",
    "cls.fit(features_train_concat,xtrain_glove)\n",
    "\n",
    "def my_scorer_reverse(ground_truth, predictions):\n",
    "    score = 0.0\n",
    "    length = len(ground_truth)\n",
    "    for i in range (length):\n",
    "        dist = []\n",
    "        current_query = ground_truth[i]\n",
    "        for j in range(length):\n",
    "            dist.append((np.linalg.norm(predictions[j]-current_query),j))\n",
    "        dist.sort()\n",
    "        rank_list = [v for (k,v) in dist[:20]]\n",
    "        if i in rank_list:\n",
    "            rank = rank_list.index(i)\n",
    "            score = score + (21.0-rank)/20.0\n",
    "    return score/length\n",
    "\n",
    "my_scorer_reverse = make_scorer(my_scorer_reverse, greater_is_better=True)\n",
    "scores = cross_val_score(cls, features_train_concat,xtrain_glove, cv=5,scoring=my_scorer_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6697999999999953\n"
     ]
    }
   ],
   "source": [
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "cls = KernelRidge(kernel='rbf',alpha=1.0)\n",
    "\n",
    "def my_scorer_reverse(ground_truth, predictions):\n",
    "    score = 0.0\n",
    "    length = len(ground_truth)\n",
    "    for i in range (length):\n",
    "        dist = []\n",
    "        current_query = ground_truth[i]\n",
    "        for j in range(length):\n",
    "            dist.append((np.linalg.norm(predictions[j]-current_query),j))\n",
    "        dist.sort()\n",
    "        rank_list = [v for (k,v) in dist[:20]]\n",
    "        if i in rank_list:\n",
    "            rank = rank_list.index(i)\n",
    "            score = score + (21.0-rank)/20.0\n",
    "    return score/length\n",
    "\n",
    "my_scorer_reverse = make_scorer(my_scorer_reverse, greater_is_better=True)\n",
    "scores = cross_val_score(cls, features_train_concat,xtrain_glove, cv=5,scoring=my_scorer_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.665725 0.67845  0.68255  0.657625 0.66465 ]\n"
     ]
    }
   ],
   "source": [
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6697999999999953\n"
     ]
    }
   ],
   "source": [
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
