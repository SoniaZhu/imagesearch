{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading tags\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Find set of supercategories, categories \n",
    "supercategory_set = set()\n",
    "category_set = set()\n",
    "for i in range (10000):\n",
    "\tfile = open(\"tags_train/\" + str(i) + \".txt\", \"r\")\n",
    "\tlines = file.readlines() \n",
    "\tfor  line in lines:\n",
    "\t\twords = line.strip().split(':')\n",
    "\t\tsupercategory_set.add(words[0])\n",
    "\t\tcategory_set.add(words[1])\n",
    "\tfile.close()\n",
    "\n",
    "# mapping from (super) category to index\n",
    "supercategory_dict = {item:val for val, item in enumerate(supercategory_set)}\n",
    "category_dict = {item:val+1 for val, item in enumerate(category_set)}\n",
    "\n",
    "# Vectorize tags\n",
    "train_tags = []\n",
    "for i in range (10000):\n",
    "\tfile = open(\"tags_train/\" + str(i) + \".txt\", \"r\")\n",
    "\tlines = file.readlines() \n",
    "\trow = np.zeros(len(supercategory_set))\n",
    "\tfor line in lines:\n",
    "\t\twords = line.strip().split(':')\t\t\n",
    "\t\tsupercategory_column = supercategory_dict.get(words[0])\n",
    "\t\tcategory_index = category_dict.get(words[1])\n",
    "\t\trow[supercategory_column] = category_index\n",
    "\ttrain_tags.append(row)\n",
    "\tfile.close()\n",
    "    \n",
    "print (\"Finished loading tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading queries\n"
     ]
    }
   ],
   "source": [
    "query = []\n",
    "with open('query_glove.csv', 'r') as csvfile:\n",
    "\tcsv_reader = csv.reader(csvfile)\n",
    "\tfor line in csv_reader:\n",
    "\t\tquery.append(line)\n",
    "print (\"Finished loading queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tags = RandomForestRegressor(max_depth=2, random_state=0,n_estimators=100)\n",
    "clf_tags.fit(query,train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading 1000-d train features \n",
    "features_train = np.zeros((10000,1000))\n",
    "with open('features_train/features_resnet1000_train.csv', 'r') as csvfile:\n",
    "\tcsv_reader = csv.reader(csvfile)\n",
    "\tfor line in csv_reader:\n",
    "\t\timage_name = line[0].strip(\".jpg\")[13:]\n",
    "\t\trow = []\n",
    "\t\tfor i in range(len(line)):\n",
    "\t\t\tif i > 0:\n",
    "\t\t\t\trow.append(float(line[i]))\t\t\n",
    "\t\tfeatures_train[int(image_name)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading 2048-d train features \n",
    "features_train_2048 = np.zeros((10000,2048))\n",
    "with open('features_train/features_resnet1000intermediate_train.csv', 'r') as csvfile:\n",
    "\tcsv_reader = csv.reader(csvfile)\n",
    "\tfor line in csv_reader:\n",
    "\t\timage_name = line[0].strip(\".jpg\")[13:]\n",
    "\t\trow = []\n",
    "\t\tfor i in range(len(line)):\n",
    "\t\t\tif i > 0:\n",
    "\t\t\t\trow.append(float(line[i]))\t\t\n",
    "\t\tfeatures_train_2048[int(image_name)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   33.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n"
     ]
    }
   ],
   "source": [
    "clf_2048 = RandomForestRegressor(max_depth=2, random_state=0,n_estimators=100,verbose=3)\n",
    "clf_2048.fit(query,features_train_2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
