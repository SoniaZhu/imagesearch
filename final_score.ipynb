{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Find set of supercategories, categories \n",
    "supercategory_set = set()\n",
    "category_set = set()\n",
    "for i in range (10000):\n",
    "\tfile = open(\"tags_train/\" + str(i) + \".txt\", \"r\")\n",
    "\tlines = file.readlines() \n",
    "\tfor  line in lines:\n",
    "\t\twords = line.strip().split(':')\n",
    "\t\tsupercategory_set.add(words[0])\n",
    "\t\tcategory_set.add(words[1])\n",
    "\tfile.close()\n",
    "\n",
    "# mapping from (super) category to index\n",
    "supercategory_dict = {item:val for val, item in enumerate(supercategory_set)}\n",
    "category_dict = {item:val+1 for val, item in enumerate(category_set)}\n",
    "\n",
    "# Vectorize train tags\n",
    "train_tags = []\n",
    "for i in range (10000):\n",
    "\tfile = open(\"tags_train/\" + str(i) + \".txt\", \"r\")\n",
    "\tlines = file.readlines() \n",
    "\trow = np.zeros(len(supercategory_set))\n",
    "\tfor line in lines:\n",
    "\t\twords = line.strip().split(':')\t\t\n",
    "\t\tsupercategory_column = supercategory_dict.get(words[0])\n",
    "\t\tcategory_index = category_dict.get(words[1])\n",
    "\t\trow[supercategory_column] = category_index\n",
    "\ttrain_tags.append(row)\n",
    "\tfile.close()\n",
    "    \n",
    "print (\"Finished loading tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading queries\n"
     ]
    }
   ],
   "source": [
    "# Load train queries\n",
    "query = []\n",
    "with open('query_glove.csv', 'r') as csvfile:\n",
    "\tcsv_reader = csv.reader(csvfile)\n",
    "\tfor line in csv_reader:\n",
    "\t\tquery.append(line)\n",
    "print (\"Finished loading queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading 1000-d train features \n",
    "features_train = np.zeros((10000,1000))\n",
    "with open('features_train/features_resnet1000_train.csv', 'r') as csvfile:\n",
    "\tcsv_reader = csv.reader(csvfile)\n",
    "\tfor line in csv_reader:\n",
    "\t\timage_name = line[0].strip(\".jpg\")[13:]\n",
    "\t\trow = []\n",
    "\t\tfor i in range(len(line)):\n",
    "\t\t\tif i > 0:\n",
    "\t\t\t\trow.append(float(line[i]))\t\t\n",
    "\t\tfeatures_train[int(image_name)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading 2048-d train features \n",
    "features_train_2048 = np.zeros((10000,2048))\n",
    "with open('features_train/features_resnet1000intermediate_train.csv', 'r') as csvfile:\n",
    "\tcsv_reader = csv.reader(csvfile)\n",
    "\tfor line in csv_reader:\n",
    "\t\timage_name = line[0].strip(\".jpg\")[13:]\n",
    "\t\trow = []\n",
    "\t\tfor i in range(len(line)):\n",
    "\t\t\tif i > 0:\n",
    "\t\t\t\trow.append(float(line[i]))\t\t\n",
    "\t\tfeatures_train_2048[int(image_name)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading queries\n"
     ]
    }
   ],
   "source": [
    "# Load test queries\n",
    "query_test = []\n",
    "with open('query_glove_test.csv', 'r') as csvfile:\n",
    "\tcsv_reader = csv.reader(csvfile)\n",
    "\tfor line in csv_reader:\n",
    "\t\tquery_test.append(line)\n",
    "print (\"Finished loading queries\")\n",
    "#tags_predict = clf_tags.predict(query_test)\n",
    "\n",
    "# Vectorize test tags\n",
    "test_tags = []\n",
    "for i in range (2000):\n",
    "\tfile = open(\"tags_test/\" + str(i) + \".txt\", \"r\")\n",
    "\tlines = file.readlines() \n",
    "\trow = np.zeros(len(supercategory_set))\n",
    "\tfor line in lines:\n",
    "\t\twords = line.strip().split(':')\t\t\n",
    "\t\tsupercategory_column = supercategory_dict.get(words[0])\n",
    "\t\tcategory_index = category_dict.get(words[1])\n",
    "\t\trow[supercategory_column] = category_index\n",
    "\ttest_tags.append(row)\n",
    "\tfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#clf_knn = KNeighborsRegressor(n_neighbors=5)\n",
    "features_train_concat = np.concatenate((np.array(features_train_2048),np.array(features_train)), axis=1)\n",
    "features_train_concat = np.concatenate((features_train_concat, np.array(train_tags)), axis=1)\n",
    "#clf_knn.fit(query,features_train_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_2048 = np.zeros((2000,2048))\n",
    "with open('features_test/features_resnet1000intermediate_test.csv', 'r') as csvfile:\n",
    "\tcsv_reader = csv.reader(csvfile)\n",
    "\tfor line in csv_reader:\n",
    "\t\timage_name = line[0].strip(\".jpg\")[12:]\n",
    "\t\trow = []\n",
    "\t\tfor i in range(len(line)):\n",
    "\t\t\tif i > 0:\n",
    "\t\t\t\trow.append(float(line[i]))\t\t\n",
    "\t\tfeatures_test_2048[int(image_name)] = row\n",
    "\n",
    "features_test_1000 = np.zeros((2000,1000))    \n",
    "with open('features_test/features_resnet1000_test.csv', 'r') as csvfile:\n",
    "\tcsv_reader = csv.reader(csvfile)\n",
    "\tfor line in csv_reader:\n",
    "\t\timage_name = line[0].strip(\".jpg\")[12:]\n",
    "\t\trow = []\n",
    "\t\tfor i in range(len(line)):\n",
    "\t\t\tif i > 0:\n",
    "\t\t\t\trow.append(float(line[i]))\t\t\n",
    "\t\tfeatures_test_1000[int(image_name)] = row\n",
    "        \n",
    "features_test_concat = np.concatenate((np.array(features_test_2048),np.array(features_test_1000)), axis=1)\n",
    "features_test_concat = np.concatenate((features_test_concat, np.array(test_tags)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(gamma=0.001)\n",
    "train_query = np.array(query,dtype=float)\n",
    "X_train_1 = np.concatenate((train_query,features_train_concat),axis=1)\n",
    "Y_train_1 = np.ones(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query_reordered = np.concatenate((train_query[5000:10000],train_query[0:5000]),axis=0)\n",
    "X_train_0 = np.concatenate((train_query_reordered,features_train_concat),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_0 = np.zeros(10000)\n",
    "X_train = np.concatenate((X_train_1,X_train_0),axis=0)\n",
    "Y_train = np.concatenate((Y_train_1,Y_train_0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_RF = RandomForestClassifier(max_depth=15, random_state=0,n_estimators=100,verbose=3)\n",
    "clf_RF.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_list = []\n",
    "test_query = np.array(query_test,dtype=float)  #2000,300\n",
    "#features_test_concat  => (2000,3060)\n",
    "for i in range (2000):\n",
    "    query_repeat = np.tile(test_query[i],(2000,1))\n",
    "    X_test = np.concatenate((query_repeat,features_test_concat),axis=1)\n",
    "    svm_predictions = clf_RF.predict_proba(X_test)\n",
    "    predictions_indices = [(svm_predictions[index][1],index) for index in range(2000)]\n",
    "    predictions_indices.sort(reverse=True)\n",
    "    rank_list.append([v for (k,v) in predictions_indices[:20]])\n",
    "def mergeTwenty(lst):\n",
    "    result = str(lst[0])+\".jpg\"\n",
    "    for i in range(1,len(lst)):\n",
    "        result += \" \" + str(lst[i]) + \".jpg\"\n",
    "    return result\n",
    "\n",
    "with open('RF_full_data_submission.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "    csv_writer.writerow([\"Descritpion_ID\", \"Top_20_Image_IDs\"])\n",
    "    for i in range(len(rank_list)):\n",
    "        csv_writer.writerow([str(i) + \".txt\", mergeTwenty(rank_list[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=20, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=20,n_jobs=-1)\n",
    "clf_KNN.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = np.array(query_test,dtype=float) \n",
    "query_repeat = np.tile(test_query[0],(2000,1))\n",
    "X_test = np.concatenate((query_repeat,features_test_concat),axis=1)\n",
    "svm_predictions = clf_KNN.predict_proba(X_test)\n",
    "predictions_indices = [(svm_predictions[index][1],index) for index in range(2000)]\n",
    "predictions_indices.sort(reverse=True)\n",
    "rank_list.append([v for (k,v) in predictions_indices[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_list = []\n",
    "test_query = np.array(query_test,dtype=float)  #2000,300\n",
    "#features_test_concat  => (2000,3060)\n",
    "for i in range (2000):\n",
    "    if i%40 == 0:\n",
    "        print (\"Running image\" + str(i))\n",
    "    query_repeat = np.tile(test_query[i],(2000,1))\n",
    "    X_test = np.concatenate((query_repeat,features_test_concat),axis=1)\n",
    "    svm_predictions = clf_KNN.predict_proba(X_test)\n",
    "    predictions_indices = [(svm_predictions[index][1],index) for index in range(2000)]\n",
    "    predictions_indices.sort(reverse=True)\n",
    "    rank_list.append([v for (k,v) in predictions_indices[:20]])\n",
    "\n",
    "def mergeTwenty(lst):\n",
    "    result = str(lst[0])+\".jpg\"\n",
    "    for i in range(1,len(lst)):\n",
    "        result += \" \" + str(lst[i]) + \".jpg\"\n",
    "    return result\n",
    "\n",
    "with open('KNN_full_data_submission.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "    csv_writer.writerow([\"Descritpion_ID\", \"Top_20_Image_IDs\"])\n",
    "    for i in range(len(rank_list)):\n",
    "        csv_writer.writerow([str(i) + \".txt\", mergeTwenty(rank_list[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 312)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_query_std = StandardScaler().fit_transform(np.array(query,dtype=float))\n",
    "\n",
    "pca_1000 = PCA(n_components=100)\n",
    "features_train_1000_PCA = pca_1000.fit_transform(StandardScaler().fit_transform(features_train))\n",
    "\n",
    "pca_2048 = PCA(n_components=200)\n",
    "features_train_2048_PCA = pca_2048.fit_transform(StandardScaler().fit_transform(features_train_2048))\n",
    "\n",
    "features_train_PCA = np.concatenate((np.array(features_train_2048_PCA),np.array(features_train_1000_PCA)), axis=1)\n",
    "features_train_PCA = np.concatenate((features_train_PCA, np.array(StandardScaler().fit_transform(train_tags))), axis=1)\n",
    "print(features_train_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 612)\n"
     ]
    }
   ],
   "source": [
    "X_train_1_PCA = np.concatenate((train_query_std,features_train_PCA),axis=1)\n",
    "train_query_reordered_PCA = np.concatenate((train_query_std[5000:10000],train_query_std[0:5000]),axis=0)\n",
    "X_train_0_PCA = np.concatenate((train_query_reordered_PCA,features_train_PCA),axis=1)\n",
    "X_train_PCA = np.concatenate((X_train_1_PCA,X_train_0_PCA),axis=0)\n",
    "print (X_train_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF_PCA = RandomForestClassifier(max_depth=15, random_state=0,n_estimators=100,verbose=3,n_jobs=-1)\n",
    "clf_RF_PCA.fit(X_train_PCA,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 312)\n"
     ]
    }
   ],
   "source": [
    "test_query_std = StandardScaler().fit_transform(np.array(test_query,dtype=float))\n",
    "features_test_1000_PCA = pca_1000.transform((StandardScaler().fit_transform(features_test_1000)))\n",
    "features_test_2048_PCA = pca_2048.transform((StandardScaler().fit_transform(features_test_2048)))\n",
    "features_test_PCA = np.concatenate((np.array(features_test_2048_PCA),np.array(features_test_1000_PCA)), axis=1)\n",
    "features_test_PCA = np.concatenate((features_test_PCA, np.array(StandardScaler().fit_transform(test_tags))), axis=1)\n",
    "print(features_test_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_list = []\n",
    "for i in range (2000):\n",
    "    if i%40 == 0:\n",
    "        print (\"Running image\" + str(i))\n",
    "    query_repeat = np.tile(test_query[i],(2000,1))\n",
    "    X_test = np.concatenate((query_repeat,features_test_PCA),axis=1)\n",
    "    svm_predictions = clf_RF_PCA.predict_proba(X_test)\n",
    "    predictions_indices = [(svm_predictions[index][1],index) for index in range(2000)]\n",
    "    predictions_indices.sort(reverse=True)\n",
    "    rank_list.append([v for (k,v) in predictions_indices[:20]])\n",
    "\n",
    "def mergeTwenty(lst):\n",
    "    result = str(lst[0])+\".jpg\"\n",
    "    for i in range(1,len(lst)):\n",
    "        result += \" \" + str(lst[i]) + \".jpg\"\n",
    "    return result\n",
    "\n",
    "with open('RF_PCA_submission.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "    csv_writer.writerow([\"Descritpion_ID\", \"Top_20_Image_IDs\"])\n",
    "    for i in range(len(rank_list)):\n",
    "        csv_writer.writerow([str(i) + \".txt\", mergeTwenty(rank_list[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "def my_scorer(ground_truth, predictions):\n",
    "    score = 0.0\n",
    "    length = len(ground_truth)\n",
    "    for i in range (length):\n",
    "        dist = []\n",
    "        for j in range(length):\n",
    "            dist.append((np.linalg.norm(predictions[i]-ground_truth[j]),j))\n",
    "        dist.sort()\n",
    "        rank_list = [v for (k,v) in dist[:20]]\n",
    "        if i in rank_list:\n",
    "            rank = rank_list.index(i)\n",
    "            score = score + (21.0-rank)/20.0\n",
    "    return score/length\n",
    "\n",
    "my_scorer = make_scorer(my_scorer, greater_is_better=True)\n",
    "scores = cross_val_score(clf_RF_PCA, X_train,Y_train, cv=5,scoring=my_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
